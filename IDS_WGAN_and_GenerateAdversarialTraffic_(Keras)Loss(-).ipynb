{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IDS_WGAN and GenerateAdversarialTraffic (Keras) (U2R&R2L)",
      "provenance": [],
      "collapsed_sections": [
        "08Q42YHGbvLT",
        "B7DnHaw3deiA",
        "rwBI6OpJZfJU",
        "VI1gaJTdcZkg"
      ],
      "toc_visible": true,
      "mount_file_id": "1weFix3T8Y_fk-qpDQp8zE29LI1Buc1bq",
      "authorship_tag": "ABX9TyNW2Dmi+U9+ImYM/68ADIFl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thetinybug/Django-Project/blob/master/IDS_WGAN_and_GenerateAdversarialTraffic_(Keras)Loss(-).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HfVbgm_IdnMH",
        "colab_type": "text"
      },
      "source": [
        "# **0. Một số biến toàn cục**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rFWSSBQF99E",
        "colab_type": "text"
      },
      "source": [
        "##**0.1 Paths**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uW-RHzMwdsG5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Modules Path\n",
        "ModulePath = \"/content/drive/My Drive/Study/KLTN/Google Colab/0.0 Python Modules/\"\n",
        "\n",
        "\n",
        "# Dataset Path\n",
        "Dataset_Path = \"/content/drive/My Drive/Study/KLTN/Dataset/NSL-KDD Processed/Final - For Using/\"\n",
        "Trainsets_Path = Dataset_Path + 'Trainset/'\n",
        "# Trainset\n",
        "g_trainset_path = Trainsets_Path + \"GAN-G.csv\"\n",
        "d_trainset_path = Trainsets_Path + \"GAN-D.csv\"\n",
        "# Testset\n",
        "testset_path = Dataset_Path + \"Testset/\" + \"KDDTest+.csv\"\n",
        "\n",
        "# Saved Models Path\n",
        "SavedModelPath = \"/content/drive/My Drive/Study/KLTN/Saved Model/\"\n",
        "\n",
        "# GAN\n",
        "GAN_SavedModelPath = SavedModelPath + \"GANModel/\"\n",
        "\n",
        "# Blackbox IDS\n",
        "IDS_DOS_ModelPath = SavedModelPath + \"IDSModel/DOS/\" + \"Keras_IDS_CNN.h5\"\n",
        "IDS_U2R_AND_R2L_ModelPath = SavedModelPath + \"IDSModel/U2R_AND_R2L/\" + \"Keras_IDS_CNN.h5\""
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XwTYqTdfF-wS",
        "colab_type": "text"
      },
      "source": [
        "##**0.2 Variables**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rBB0NLwGAce",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Choose Attack Category\n",
        "ATTACK_CATEGORY = 'DOS'"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZkqASdBS-QA",
        "colab_type": "text"
      },
      "source": [
        "#**1. Chuẩn bị**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m27n3nFSTSv2",
        "colab_type": "text"
      },
      "source": [
        "##1.1 Thư viện"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08Q42YHGbvLT",
        "colab_type": "text"
      },
      "source": [
        "###1.1.1. Cài đặt các thư viện cần thiết"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7ZZvZaAbM1J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "72e5a356-11a2-412f-d4c5-761802e256a5"
      },
      "source": [
        "!pip3 install numpy adabound torc sklearn matplotlib pandas"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.18.5)\n",
            "Requirement already satisfied: adabound in /usr/local/lib/python3.6/dist-packages (0.0.5)\n",
            "Requirement already satisfied: torc in /usr/local/lib/python3.6/dist-packages (0.1.0)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (0.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (3.2.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (1.0.5)\n",
            "Requirement already satisfied: torch>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from adabound) (1.5.1+cu101)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn) (0.22.2.post1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.2.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.4.7)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=0.4.0->adabound) (0.16.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (0.15.1)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.4.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zSLjr5W9rI-8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "42e3723e-77d5-44c3-8fd1-807922a03c5b"
      },
      "source": [
        "# Lib for print table\n",
        "!pip3 install prettytable"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: prettytable in /usr/local/lib/python3.6/dist-packages (0.7.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mt5O3Y-fb5Du",
        "colab_type": "text"
      },
      "source": [
        "###1.1.2. Import thư viện"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONDkO5xKdjqa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Add Module Path - To Import Custom Modules\n",
        "import sys\n",
        "sys.path.append(ModulePath)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YIQ708lZS2lF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "70ee7d96-9095-4293-e205-e636df11407f"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch as th\n",
        "from torch.autograd import Variable as V\n",
        "import torch.autograd as autograd\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Libs for Keras\n",
        "from keras.models import load_model\n",
        "\n",
        "\n",
        "# Own Custom Module to import models and constants\n",
        "from models import *\n",
        "from constants import *\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import adabound \n",
        "import math\n",
        "from prettytable import PrettyTable"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Ljsym5CVV0f",
        "colab_type": "text"
      },
      "source": [
        "##1.2 Hàm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5oYEYxfYiCP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# BlackboxIDS = DefaultBlackboxIDS\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fx9YxoggWOY2",
        "colab_type": "text"
      },
      "source": [
        "###1.2.1 Tạo Batch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wA-LxbnzWXyS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Hàm tạo Batch\n",
        "def create_batch2(x,batch_size):\n",
        "    a = list(range(len(x)))\n",
        "    np.random.shuffle(a)\n",
        "\n",
        "    x = x[a]\n",
        "    batch_x = [x[batch_size * i : (i+1)*batch_size,:] for i in range(len(x)//batch_size)]\n",
        "\n",
        "    return batch_x"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNK9nlNgWPvJ",
        "colab_type": "text"
      },
      "source": [
        "###1.2.2 Tiền xử lý dữ liệu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iwpT6Jm8WRTb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Hàm tiền xử lý dữ liệu tấn công\n",
        "def preprocess_malicious_data(dataset, attack_category):\n",
        "    # 2 Category: DoS, U2R&R2L\n",
        "    if attack_category != 'DOS' and attack_category != 'U2R_AND_R2L':\n",
        "      raise ValueError(\"Preprocess Data Fail: Invalid Attack Category\")\n",
        "\n",
        "    if attack_category == 'DOS':\n",
        "      # DOS \n",
        "      attack_data = dataset[dataset['class'] == 'DOS']\n",
        "    else:\n",
        "      # U2R_AND_R2L\n",
        "      attack_data = dataset[dataset['class'] == 'U2R_AND_R2L']\n",
        "\n",
        "    # Del label\n",
        "    del attack_data[\"class\"]\n",
        "\n",
        "    return np.array(attack_data)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eKp_B9PvboG_",
        "colab_type": "text"
      },
      "source": [
        "###1.2.3 Hàm tạo Noise\n",
        "  - **DOS**: \n",
        "    - **Giữ lại**: Intrinsic, Time-based traffic.\n",
        "    - **Thay đổi**: Content, Host-based traffic.\n",
        "  - **U2R&R2L**:\n",
        "    - **Giữ lại**: Intrinsic, Content.\n",
        "    - **Thay đổi**: Time-based traffic, Host-based traffic."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idpQZ6kCfBrO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Make Noise\n",
        "def MakeNoise(attack_category, n_feature, n_record):\n",
        "    if attack_category != 'DOS' and attack_category != 'U2R_AND_R2L':\n",
        "      raise ValueError(\"Preprocess Data Fail: Invalid Attack Category\")\n",
        "\n",
        "    # Create noise array\n",
        "    noise = np.random.uniform(-1,1,(n_feature,n_record))\n",
        "\n",
        "    # retain feature\n",
        "    # DOS : INTRINSIC, TIMEBASED\n",
        "    if attack_category == 'DOS':\n",
        "      noise[:, INTRINSIC_INDEX + TIMEBASED_INDEX] = 0\n",
        "    else:\n",
        "      # U2R&R2L: INTRINSIC, CONTENT\n",
        "      noise[:, INTRINSIC_INDEX + CONTENT_INDEX] = 0\n",
        "    \n",
        "    return noise"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wquWhjq3THhT",
        "colab_type": "text"
      },
      "source": [
        "##1.3 Chuẩn bị dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7RXVPU_HTk30",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "c5781f6b-42fa-452a-b25b-c8fea87d80ac"
      },
      "source": [
        "## Prepare Dataset\n",
        "g_train_data = pd.read_csv(g_trainset_path)\n",
        "d_train_data = pd.read_csv(d_trainset_path)\n",
        "\n",
        "# All attack record in train_data\n",
        "raw_attack = preprocess_malicious_data(g_train_data, ATTACK_CATEGORY)\n",
        "# All normal record in train_data\n",
        "del d_train_data[\"class\"]\n",
        "normal = np.array(d_train_data)\n",
        "\n",
        "# batch_size, epoch, critic_iters\n",
        "NUMBER_OF_FEATURES = len(d_train_data.columns)\n",
        "BATCH_SIZE = 64\n",
        "MAX_EPOCH = 100\n",
        "\n",
        "\n",
        "print(\"Amout of Generator Trainset:\", g_train_data.shape[0])\n",
        "print(\"Amout of Discriminator Trainset:\", d_train_data.shape[0])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Amout of Generator Trainset: 23488\n",
            "Amout of Discriminator Trainset: 33672\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mvFic38lQx5p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b3aeb9fd-b5ed-4355-c671-51791a0fa1d0"
      },
      "source": [
        "print(g_train_data.shape)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(23488, 42)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otbVJEAzcTv4",
        "colab_type": "text"
      },
      "source": [
        "# **2. Định nghĩa Model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NsF64RDMaBFc",
        "colab_type": "text"
      },
      "source": [
        "##**2.1. Tạo Model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVn0MzP1HW_0",
        "colab_type": "text"
      },
      "source": [
        "###2.1.1. GAN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sqogk9lIw_Uk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# GAN Model\n",
        "# GAN - Generator\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self,input_dim, output_dim):\n",
        "        super(Generator, self).__init__()\n",
        "        self.layer = nn.Sequential(\n",
        "            nn.Linear(input_dim, input_dim//2),\n",
        "            nn.ReLU(True),\n",
        "            nn.Linear(input_dim //2, input_dim//2),\n",
        "            nn.ReLU(True),\n",
        "            nn.Linear(input_dim // 2, input_dim//2),\n",
        "            nn.ReLU(True),\n",
        "            nn.Linear(input_dim//2,input_dim//2),\n",
        "            nn.ReLU(True),\n",
        "            nn.Linear(input_dim//2,output_dim),\n",
        "            # 08/05 - Add Tanh func.\n",
        "            nn.Tanh()\n",
        "        )\n",
        "    def forward(self, noise):\n",
        "        output = self.layer(noise)\n",
        "        # return restrict output in range[0,1]\n",
        "        return th.clamp(output,0.,1.)\n",
        "\n",
        "# GAN - Discriminator\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self,input_dim, output_dim):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.layer = nn.Sequential(\n",
        "            nn.Linear(input_dim, input_dim*2),\n",
        "            nn.LeakyReLU(True),\n",
        "            nn.Linear(input_dim * 2, input_dim *2),\n",
        "            nn.LeakyReLU(True),\n",
        "            nn.Linear(input_dim*2 , input_dim*2),\n",
        "            nn.LeakyReLU(True),\n",
        "            nn.Linear(input_dim*2,input_dim//2),\n",
        "            nn.LeakyReLU(True),\n",
        "            nn.Linear(input_dim//2,output_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self,x):\n",
        "        return self.layer(x)\n",
        "\n",
        "# Retain feature\n",
        "def Retain_Features(adversarial, raw, attack_category):\n",
        "    if attack_category != 'DOS' and attack_category != 'U2R_AND_R2L':\n",
        "        raise ValueError(\"Preprocess Data Fail: Invalid Attack Category\")\n",
        "\n",
        "    for idx, adversarial_val in enumerate(adversarial):\n",
        "        if attack_category == 'DOS':\n",
        "            adversarial_val[DOS_FEATURES] = raw[idx][DOS_FEATURES]\n",
        "        else:\n",
        "            adversarial_val[U2R_AND_R2L_FEATURES] = raw[idx][U2R_AND_R2L_FEATURES]\n",
        "    \n",
        "    return adversarial\n",
        "\n",
        "\n",
        "# Instantiate Model Class\n",
        "D_G_INPUT_DIM = NUMBER_OF_FEATURES        # Number of dimension from dataset\n",
        "G_OUTPUT_DIM = NUMBER_OF_FEATURES         # Number of dimension from dataset\n",
        "D_OUTPUT_DIM = 1                          # A value [0,1] mean it is Normal Traffic or Arnomaly Traffic\n",
        "LAMBDA = 10                               # Gradient penalty lambda hyperparameter\n",
        "CRITIC_ITERS = 5                          # For WGAN and WGAN-GP, number of critic iters per gen iter\n",
        "CLAMP = 0.01\n",
        "\n",
        "# Create GAN Models\n",
        "generator = Generator(D_G_INPUT_DIM,G_OUTPUT_DIM)\n",
        "discriminator = Discriminator(D_G_INPUT_DIM,D_OUTPUT_DIM)\n",
        "\n",
        "# Adam Optimizer \n",
        "learning_rate = 0.0001\n",
        "optimizer_G = optim.RMSprop(generator.parameters(), lr=learning_rate)\n",
        "optimizer_D = optim.RMSprop(discriminator.parameters(), lr=learning_rate)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VnmTHYMrHiv6",
        "colab_type": "text"
      },
      "source": [
        "###2.1.2 IDS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JhG8mKiFcO1-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "outputId": "9edd025d-e483-48f8-ef97-5659132b733b"
      },
      "source": [
        "# Keras Model\n",
        "ids_model = load_model(IDS_DOS_ModelPath)\n",
        "ids_model.summary()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_3 (Conv1D)            (None, 38, 128)           640       \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 4864)              0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 4864)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 128)               622720    \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 128)               512       \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 2)                 258       \n",
            "=================================================================\n",
            "Total params: 624,130\n",
            "Trainable params: 623,874\n",
            "Non-trainable params: 256\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxaOwvpkaExE",
        "colab_type": "text"
      },
      "source": [
        "##2.2. Hàm tính Penalty"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8hcustBttFV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compute Gradient Penalty\n",
        "def compute_gradient_penalty(D, normal_t, attack_t):\n",
        "    alpha = th.Tensor(np.random.random((normal_t.shape[0], 1)))\n",
        "    between_n_a = (alpha * normal_t + ((1 - alpha) * attack_t)).requires_grad_(True)\n",
        "    d_between_n_a = D(between_n_a)\n",
        "    adv = V(th.Tensor(normal_t.shape[0], 1).fill_(1.0), requires_grad=False)\n",
        "\n",
        "    gradients = autograd.grad(\n",
        "        outputs=d_between_n_a,\n",
        "        inputs=between_n_a,\n",
        "        grad_outputs=adv,\n",
        "        create_graph=True,\n",
        "        retain_graph=True,\n",
        "        only_inputs=True,\n",
        "    )[0]\n",
        "    gradients = gradients.view(gradients.size(0), -1)\n",
        "    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
        "    return gradient_penalty"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDp5Uy_HaShp",
        "colab_type": "text"
      },
      "source": [
        "# **3. Run Model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s8tEzhBNxvGM",
        "colab_type": "text"
      },
      "source": [
        "##**3.1 Run IDSGAN**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FIMcufKLkuf1",
        "colab_type": "text"
      },
      "source": [
        "###**3.1.1 Run IDSGAN**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9C1uFo0vnv7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "outputId": "994d0f08-fb30-4b84-be50-5c1cf5aa9c4a"
      },
      "source": [
        "d_losses,g_losses = [],[]\n",
        "# ids_model.eval()\n",
        "generator.train()\n",
        "discriminator.train()\n",
        "\n",
        "IDS_MODEL = 'CNN'\n",
        "\n",
        "# Create batch of attack traffic\n",
        "batch_attack = create_batch2(raw_attack,BATCH_SIZE)\n",
        "\n",
        "print(\"***IDSGAN start training\")\n",
        "print(f\"#ATTACK CATEGORY: {ATTACK_CATEGORY}; IDS MODEL: {IDS_MODEL}\")\n",
        "\n",
        "table_result = PrettyTable(['Epoch', 'G-Loss', 'D-Loss'])\n",
        "print(f\"{5*' '}Epoch{15*' '}G-Loss{18*' '}D-Loss\")\n",
        "\n",
        "for epoch in range(10):\n",
        "# for epoch in range(MAX_EPOCH):\n",
        "    cnt = 0\n",
        "    # print(f\"Epoch    {epoch}---\")\n",
        "    # Comment - Mỗi train epoch tạo batch 1 lần\n",
        "    batch_normal = create_batch2(normal,BATCH_SIZE)\n",
        "    run_g_loss = 0.\n",
        "    run_d_loss = 0.\n",
        "    for idx, bn in enumerate(batch_normal):\n",
        "        normal_b = th.Tensor(bn.astype(\"float64\"))\n",
        "        #  Train Generator\n",
        "        for p in discriminator.parameters():  \n",
        "            p.requires_grad = False\n",
        "    \n",
        "        optimizer_G.zero_grad()        \n",
        "        \n",
        "        # Create Adversarial Attack Traffic\n",
        "        attack_traffic = V(th.Tensor(batch_attack[idx % len(batch_attack)]))\n",
        "        noise = MakeNoise(ATTACK_CATEGORY, len(attack_traffic), D_G_INPUT_DIM)\n",
        "        z = V(th.Tensor(noise))\n",
        "\n",
        "        adversarial_attack = generator(z)\n",
        "        adversarial_attack = Retain_Features(adversarial_attack, attack_traffic, ATTACK_CATEGORY)\n",
        "\n",
        "\n",
        "        D_pred = discriminator(adversarial_attack)\n",
        "        # # 26/06 - g_loss = -th.mean(D_pred) -> Doi thanh nhu bai bao o duoi\n",
        "        # g_loss = th.mean(D_pred)\n",
        "\n",
        "        # Giu nguyen\n",
        "        g_loss = -th.mean(D_pred)\n",
        "\n",
        "        g_loss.backward()\n",
        "        optimizer_G.step()\n",
        "        \n",
        "        run_g_loss += g_loss.item()\n",
        "        # Train Discreminator\n",
        "        for p in discriminator.parameters(): \n",
        "            p.requires_grad = True\n",
        "\n",
        "        for c in range(CRITIC_ITERS):\n",
        "            optimizer_D.zero_grad()\n",
        "            for p in discriminator.parameters():\n",
        "                p.data.clamp_(-CLAMP, CLAMP)\n",
        "                \n",
        "            ids_input = th.cat((adversarial_attack,normal_b))\n",
        "\n",
        "            # Shuffle Input\n",
        "            l = list(range(len(ids_input)))\n",
        "            np.random.shuffle(l)\n",
        "            ids_input = V(th.Tensor(ids_input[l]))\n",
        "            # Change Format for Keras\n",
        "            ids_input_keras = ids_input.reshape(ids_input.shape[0], NUMBER_OF_FEATURES, 1)\n",
        "            ids_pred = ids_model.predict(ids_input_keras)\n",
        "            # to torch.tensor\n",
        "            ids_pred = V(th.Tensor(ids_pred))\n",
        "            ids_pred_lable = th.argmax(nn.Sigmoid()(ids_pred),dim = 1).detach().numpy()\n",
        "\n",
        "            pred_normal = ids_input.numpy()[ids_pred_lable==0]\n",
        "            pred_attack = ids_input.numpy()[ids_pred_lable==1]\n",
        "            \n",
        "\n",
        "            if len(pred_attack) == 0:\n",
        "                cnt += 1\n",
        "                break\n",
        "            D_noraml = discriminator(V(th.Tensor(pred_normal)))\n",
        "            D_attack= discriminator(V(th.Tensor(pred_attack)))\n",
        "            \n",
        "            loss_normal = th.mean(D_noraml)\n",
        "            loss_attack = th.mean(D_attack)\n",
        "            # gradient_penalty = compute_gradient_penalty(discriminator, normal_b.data, adversarial_attack.data)\n",
        "            \n",
        "            # 26/06 - d_loss = loss_attack - loss_normal -> Doi thanh nhu bai bao o duoi\n",
        "            # d_loss =  loss_normal - loss_attack #+ LAMBDA * gradient_penalty\n",
        "\n",
        "            # Giu nguyen\n",
        "            d_loss = loss_attack - loss_normal\n",
        "\n",
        "            d_loss.backward()\n",
        "            optimizer_D.step()\n",
        "            run_d_loss += d_loss.item()\n",
        "            \n",
        "    d_losses.append(run_d_loss/CRITIC_ITERS)\n",
        "    g_losses.append(run_g_loss)\n",
        "    print(f\"{5*' '}{epoch:5d}{15*' '}{run_g_loss:3.4f}{18*' '}{run_d_loss/CRITIC_ITERS:3.4f}\")\n",
        "    # print(f\"G_Loss = {run_g_loss} \\t D_Loss = {run_d_loss/CRITIC_ITERS}\")\n",
        "    \n",
        "    table_result.add_row([epoch, run_g_loss, run_d_loss/CRITIC_ITERS])\n",
        "\n",
        "    if cnt >= (len(normal)/BATCH_SIZE):\n",
        "        print(\"Not exist predicted attack traffic\")\n",
        "        break\n",
        "print(\"IDSGAN finish training\")\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "***IDSGAN start training\n",
            "#ATTACK CATEGORY: DOS; IDS MODEL: CNN\n",
            "     Epoch               G-Loss                  D-Loss\n",
            "         0               -7.4549                -1.2934\n",
            "         1               -7.5656                -1.2665\n",
            "         2               -6.9964                -1.2967\n",
            "         3               -6.6135                -1.2765\n",
            "         4               -6.0895                -1.3107\n",
            "         5               -6.3380                -1.2722\n",
            "         6               -5.9661                -1.2686\n",
            "         7               -6.0266                -1.2777\n",
            "         8               -6.1959                -1.2936\n",
            "         9               -6.0031                -1.2985\n",
            "IDSGAN finish training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CslCNmNJLbKF",
        "colab_type": "text"
      },
      "source": [
        "***Thứ tự của D-Loss và G-Loss ở trên bị lộn. Ở bảng phía dưới là chính xác***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDOWyEUwxO6B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "outputId": "0804417f-6a1a-419f-ff7f-d15431a38d9c"
      },
      "source": [
        "print(table_result)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+---------------------+---------------------+\n",
            "| Epoch |        G-Loss       |        D-Loss       |\n",
            "+-------+---------------------+---------------------+\n",
            "|   0   |  -7.45486675389111  | -1.2934133229777216 |\n",
            "|   1   |  -7.565618351101875 | -1.2665405141189694 |\n",
            "|   2   |  -6.996428198181093 | -1.2967274780385196 |\n",
            "|   3   |  -6.613500509411097 | -1.2765142639167606 |\n",
            "|   4   |  -6.089539566077292 | -1.3107234163209796 |\n",
            "|   5   |  -6.337970092892647 | -1.2721560976468027 |\n",
            "|   6   |  -5.966067174449563 | -1.2686306161805987 |\n",
            "|   7   |  -6.026587700471282 | -1.2777475918643177 |\n",
            "|   8   |  -6.195909616537392 |  -1.293563328217715 |\n",
            "|   9   | -6.0030783880501986 | -1.2984525254927575 |\n",
            "+-------+---------------------+---------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdCgbMhQkz8u",
        "colab_type": "text"
      },
      "source": [
        "###**3.1.2 Show Graph**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdAqWOzkHfSd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "outputId": "525be307-391f-4a8a-aed6-bf1d5fac0e8f"
      },
      "source": [
        "# Show Graph\n",
        "plt.plot(d_losses,label = \"D_loss\")\n",
        "plt.plot(g_losses, label = \"G_loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "seo3uZ1yk4qF",
        "colab_type": "text"
      },
      "source": [
        "###**3.1.3 Save Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xG09yA2D9bzg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "GAN_G_Model_Path = GAN_SavedModelPath + \"Generator/\" + IDS_MODEL+ \"_\" + ATTACK_CATEGORY + \"_\" + str(MAX_EPOCH) + \"epoch.pth\"\n",
        "GAN_D_Model_Path = GAN_SavedModelPath + \"Discriminator/\" + IDS_MODEL+ \"_\" + ATTACK_CATEGORY + \"_\" + str(MAX_EPOCH) + \"epoch.pth\""
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aqcVgG5OT3jz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save Model\n",
        "th.save(generator.state_dict(), GAN_G_Model_Path)\n",
        "th.save(discriminator.state_dict(), GAN_D_Model_Path)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQNXCNMEx1bn",
        "colab_type": "text"
      },
      "source": [
        "##**3.2 Run Generate Adversarial Traffic**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7DnHaw3deiA",
        "colab_type": "text"
      },
      "source": [
        "###**3.2.0 Hàm tạo Batch**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvltl95vdjxa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Hàm tạo Batch\n",
        "def create_batch2(x,batch_size):\n",
        "    a = list(range(len(x)))\n",
        "    np.random.shuffle(a)\n",
        "    x = x[a]\n",
        "    batch_x = [x[batch_size * i : (i+1)*batch_size,:] for i in range(len(x)//batch_size)]\n",
        "    return batch_x"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rwBI6OpJZfJU",
        "colab_type": "text"
      },
      "source": [
        "###**3.2.1 Load Testset**\n",
        "- test_raw_attack: Tất cả Malicious record của 1 loại tấn công(ATTACK_CATEGORY) trong KDDTest+.\n",
        "- test_normal: Tất cả Normal record trong KDDTest+.\n",
        "\n",
        "**Label**\n",
        "- test_raw_attack: 1\n",
        "- test_normal: 0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cw0Mb9NXZkQX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "4224518e-3d57-433b-e643-299a69b009a1"
      },
      "source": [
        "# Load Testset\n",
        "testset = pd.read_csv(testset_path)\n",
        "\n",
        "# test_raw_attack\n",
        "test_raw_attack = preprocess_malicious_data(testset, ATTACK_CATEGORY)\n",
        "# test_normal\n",
        "test_normal = np.array(testset[testset[\"class\"] == 'Normal'])[:,:-1]\n",
        "\n",
        "print(f\"Amount of {ATTACK_CATEGORY} in testset:\\t{len(test_raw_attack)}\")\n",
        "print(f\"Amount of Normal in testset:\\t{len(test_normal)}\")"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Amount of DOS in testset:\t7460\n",
            "Amount of Normal in testset:\t9711\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VI1gaJTdcZkg",
        "colab_type": "text"
      },
      "source": [
        "###**3.2.2 Read Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0w_F6zKcgrF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "b832112e-1c63-4026-9364-46016f54416b"
      },
      "source": [
        "# Declare Batch size and Dimensions\n",
        "BATCH_SIZE = 256 # Batch size\n",
        "D_G_INPUT_DIM = test_normal.shape[1]\n",
        "G_OUTPUT_DIM =test_normal.shape[1] \n",
        "D_OUTPUT_DIM = 1\n",
        "\n",
        "# Read model\n",
        "# Read GAN-G\n",
        "random_g = Generator(D_G_INPUT_DIM,G_OUTPUT_DIM)\n",
        "leaned_g = Generator(D_G_INPUT_DIM,G_OUTPUT_DIM)\n",
        "# Load Param for GAN-G Learned\n",
        "g_param = th.load(GAN_G_Model_Path,map_location=lambda x,y:x)\n",
        "leaned_g.load_state_dict(g_param)\n",
        "\n",
        "# Keras Model\n",
        "ids_model = load_model(IDS_DOS_ModelPath)\n",
        "ids_model.summary()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_3 (Conv1D)            (None, 38, 128)           640       \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 4864)              0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 4864)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 128)               622720    \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 128)               512       \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 2)                 258       \n",
            "=================================================================\n",
            "Total params: 624,130\n",
            "Trainable params: 623,874\n",
            "Non-trainable params: 256\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "juXEbMEJc6nM",
        "colab_type": "text"
      },
      "source": [
        "###**3.2.3 Generate Traffic**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZhPpd8MCx10u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "b728280e-26d2-4adc-a105-bca920d547d4"
      },
      "source": [
        "model_g = {\"No Train Model\":random_g,\"Trained Model\":leaned_g}\n",
        "\n",
        "# Create batch of attack traffic\n",
        "batch_attack = create_batch2(test_raw_attack,BATCH_SIZE)\n",
        "n_batch_attack = len(batch_attack)\n",
        "\n",
        "test_batch_normal = create_batch2(test_normal,BATCH_SIZE)\n",
        "\n",
        "print(f\"Num. Attack Batchs: {n_batch_attack}\")\n",
        "print(f\"Num. Normal Batchs: {len(test_batch_normal)}\")\n",
        "\n",
        "print(\"Adversarial Traffic Evaluating\")\n",
        "print(\"-\"*100)\n",
        "for model_name,g in model_g.items():\n",
        "    o_dr,a_dr,eir=[],[],[]\n",
        "    g.eval()\n",
        "    with th.no_grad():\n",
        "        for idx, bn in enumerate(test_batch_normal):\n",
        "            normal_b = th.Tensor(bn.astype(\"float64\"))\n",
        "\n",
        "            # Gen Adversarial Traffic\n",
        "            attack_traffic = V(th.Tensor(batch_attack[idx % n_batch_attack]))\n",
        "            noise = MakeNoise(ATTACK_CATEGORY, len(attack_traffic), D_G_INPUT_DIM)\n",
        "            z = V(th.Tensor(noise))\n",
        "\n",
        "            adversarial_attack = generator(z)\n",
        "            adversarial_attack = Retain_Features(adversarial_attack, attack_traffic, ATTACK_CATEGORY)\n",
        "                        \n",
        "            batch_a = th.Tensor(attack_traffic)\n",
        "\n",
        "            # IDS Input\n",
        "            ori_input = th.cat((batch_a,normal_b))\n",
        "            adv_input = th.cat((adversarial_attack,normal_b))\n",
        "            l = list(range(len(ori_input)))\n",
        "            np.random.shuffle(l)\n",
        "            adv_input = adv_input[l]\n",
        "            ori_input = ori_input[l]\n",
        "\n",
        "            adv_input = adv_input.reshape(adv_input.shape[0], NUMBER_OF_FEATURES, 1)\n",
        "            ori_input = ori_input.reshape(ori_input.shape[0], NUMBER_OF_FEATURES, 1)\n",
        "\n",
        "            ids_pred_adv = ids_model.predict(adv_input)\n",
        "            ids_pred_ori = ids_model.predict(ori_input)\n",
        "            # To Torch\n",
        "            ids_pred_adv = V(th.Tensor(ids_pred_adv))\n",
        "            ids_pred_ori = V(th.Tensor(ids_pred_ori))\n",
        "            # IDS input co dang: attack (BATCH_SIZE phan tu) --> normal (BATCH_SIZE phan tu)\n",
        "            ids_true_label = np.r_[np.ones(BATCH_SIZE),np.zeros(BATCH_SIZE)][l]\n",
        "            pred_label_adv = th.argmax(nn.Sigmoid()(ids_pred_adv),dim = 1).cpu().numpy()\n",
        "            pred_label_ori = th.argmax(nn.Sigmoid()(ids_pred_ori),dim = 1).cpu().numpy()\n",
        "            \n",
        "            \n",
        "            tn1, fn1, fp1, tp1 = confusion_matrix(ids_true_label,pred_label_adv).ravel()\n",
        "            tn2, fn2, fp2, tp2 = confusion_matrix(ids_true_label,pred_label_ori).ravel()\n",
        "\n",
        "            # print(f\"tn1, fn1, fp1, tp1 = {tn1, fn1, fp1, tp1}\")\n",
        "            # print(f\"tn2, fn2, fp2, tp2 = {tn2, fn2, fp2, tp2}\")\n",
        "\n",
        "            o_dr.append(tp2/(tp2 + fp2))\n",
        "            a_dr.append(tp1/(tp1 + fp1))\n",
        "            eir.append(1 - (tp1/(tp1 + fp1))/(tp2/(tp2 + fp2)))\n",
        "    print(f\"{model_name}\\t =>\\tOrigin DR : {np.mean(o_dr)*100:.2f}% \\t Adversarial DR : {np.mean(a_dr)*100:.2f}% \\t EIR : {np.mean(eir)*100:.2f}%\")   \n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Num. Attack Batchs: 29\n",
            "Num. Normal Batchs: 37\n",
            "Adversarial Traffic Evaluating\n",
            "----------------------------------------------------------------------------------------------------\n",
            "No Train Model\t =>\tOrigin DR : 80.01% \t Adversarial DR : 0.91% \t EIR : 98.86%\n",
            "Trained Model\t =>\tOrigin DR : 80.01% \t Adversarial DR : 0.82% \t EIR : 98.97%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwWugTozppL5",
        "colab_type": "text"
      },
      "source": [
        "The Saved Model stored in [Google Drive - GAN Model](https://drive.google.com/drive/u/1/folders/1VNFW-k5SbR0eGsJ_np3U-W3Rcz_n4I8N)\n",
        "\n",
        "The Result of Code stored in [Github - Thesis](https://github.com/thetinybug/thesis-IDSGAN)"
      ]
    }
  ]
}