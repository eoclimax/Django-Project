{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GAN and Gen/PyTorch/SVM.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "s8tEzhBNxvGM"
      ],
      "toc_visible": true,
      "mount_file_id": "1_Z-mpmb4HQAKT5RFrj9OrXqPQ5Xi4diR",
      "authorship_tag": "ABX9TyPomktfkDblxkIVjRBMxSab",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thetinybug/Django-Project/blob/master/GAN%20and%20Gen/PyTorch/SVM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m27n3nFSTSv2",
        "colab_type": "text"
      },
      "source": [
        "#**0. Thư viện**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08Q42YHGbvLT",
        "colab_type": "text"
      },
      "source": [
        "##Cài đặt "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7ZZvZaAbM1J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "e29402f2-549c-4c8c-ee14-4d8c7a12fd0b"
      },
      "source": [
        "!pip3 install adabound\n",
        "# !pip3 numpy torc sklearn matplotlib pandas"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: adabound in /usr/local/lib/python3.6/dist-packages (0.0.5)\n",
            "Requirement already satisfied: torch>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from adabound) (1.5.1+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch>=0.4.0->adabound) (1.18.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=0.4.0->adabound) (0.16.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zSLjr5W9rI-8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "16c70fc2-93ae-4d95-d4f6-fe061b25a7e4"
      },
      "source": [
        "# Lib for print table\n",
        "!pip3 install prettytable"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: prettytable in /usr/local/lib/python3.6/dist-packages (0.7.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mt5O3Y-fb5Du",
        "colab_type": "text"
      },
      "source": [
        "##Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONDkO5xKdjqa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Add Module Path - To Import Custom Modules\n",
        "# Modules Path\n",
        "ModulePath = \"/content/drive/My Drive/Study/KLTN/Google Colab/0.0 Python Modules/\"\n",
        "\n",
        "import sys\n",
        "sys.path.append(ModulePath)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YIQ708lZS2lF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "d75e632e-710f-466f-b578-ee9ea430e20a"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch as th\n",
        "from torch.autograd import Variable as V\n",
        "import torch.autograd as autograd\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Libs for Keras\n",
        "from keras.models import load_model\n",
        "\n",
        "\n",
        "# Own Custom Module to import models and constants\n",
        "from models import *\n",
        "from constants import *\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import adabound \n",
        "import math\n",
        "from prettytable import PrettyTable\n",
        "import os\n",
        "from datetime import date\n",
        "import timeit"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZkqASdBS-QA",
        "colab_type": "text"
      },
      "source": [
        "#**1. Chuẩn bị**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rFWSSBQF99E",
        "colab_type": "text"
      },
      "source": [
        "##Paths"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uW-RHzMwdsG5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Base Path\n",
        "base_path = \"/content/drive/My Drive/Study/KLTN/\"\n",
        "Dataset_Path = base_path + \"Dataset/NSL-KDD Processed/Final - For Using/\"\n",
        "SavedModelPath = base_path + \"Saved Model/\"\n",
        "\n",
        "# Dataset Path\n",
        "Trainsets_Path = Dataset_Path + 'Trainset/'\n",
        "g_trainset_path = Trainsets_Path + \"GAN-G.csv\"\n",
        "d_trainset_path = Trainsets_Path + \"GAN-D.csv\"\n",
        "testset_path = Dataset_Path + \"Testset/\" + \"KDDTest+.csv\"\n",
        "\n",
        "\n",
        "# GAN Saved Models Paths\n",
        "GAN_Model_Path = SavedModelPath + 'GANModel/'\n",
        "\n",
        "# IDS Pytorch Saved Models Paths\n",
        "IDS_Model_Path = SavedModelPath + 'IDSModel/'"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XwTYqTdfF-wS",
        "colab_type": "text"
      },
      "source": [
        "##Global Variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rBB0NLwGAce",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Global Variables\n",
        "N_FEATURES = 41\n",
        "# IDS\n",
        "IDS_INPUT_DIM = N_FEATURES\n",
        "IDS_OUTPUT_DIM = 2\n",
        "ATTACK_CATEGORIES = ['DOS', 'U2R_AND_R2L']\n",
        "\n",
        "POS_FUNCTIONAL_FEATURES = {'DOS': DOS_FEATURES, 'U2R_AND_R2L': U2R_AND_R2L_FEATURES}\n",
        "POS_NONFUNCTIONAL_FEATURES = {}\n",
        "for attack_category, pos_functional_feature in POS_FUNCTIONAL_FEATURES.items():\n",
        "    pos_nonfunctional_feature = []\n",
        "    for i in range(N_FEATURES):\n",
        "        if i not in pos_functional_feature:\n",
        "            pos_nonfunctional_feature.append(i)\n",
        "    POS_NONFUNCTIONAL_FEATURES[attack_category] = pos_nonfunctional_feature\n",
        "\n",
        "IDS_MODELS = {'DEFAULT': DefaultBlackboxIDS, 'SVM': SVM, 'MLP': MLP, 'LR': LR}"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hlE7gDk07ybi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "68a317c8-8233-410a-ed13-19feac445c16"
      },
      "source": [
        "print('Position of Functional Features\\n  ', POS_FUNCTIONAL_FEATURES)\n",
        "print('Position of Functional Features:\\n  ', POS_NONFUNCTIONAL_FEATURES)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Position of Functional Features\n",
            "   {'DOS': [0, 1, 2, 3, 4, 5, 6, 7, 8, 23, 24, 25, 26, 27, 28, 29, 30], 'U2R_AND_R2L': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22]}\n",
            "Position of Functional Features:\n",
            "   {'DOS': [9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40], 'U2R_AND_R2L': [23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otbVJEAzcTv4",
        "colab_type": "text"
      },
      "source": [
        "# **2. Định nghĩa Model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVn0MzP1HW_0",
        "colab_type": "text"
      },
      "source": [
        "##Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sqogk9lIw_Uk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load from model.py module"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MdPRWEuxBAcd",
        "colab_type": "text"
      },
      "source": [
        "##Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TcJBwwXf924F",
        "colab_type": "text"
      },
      "source": [
        "### Processing Data Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r81eRs5hx8Lf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Processing Data Functions\n",
        "# create_batch2 - Hàm tạo Batch\n",
        "def create_batch2(x,batch_size):\n",
        "    a = list(range(len(x)))\n",
        "    np.random.shuffle(a)\n",
        "    x = x[a]\n",
        "    batch_x = [x[batch_size * i : (i+1)*batch_size,:] for i in range(len(x)//batch_size)]\n",
        "    return np.array(batch_x)\n",
        "# preprocess_malicious_data - Hàm tiền xử lý dữ liệu tấn công\n",
        "def preprocess_malicious_data(dataset, attack_category):\n",
        "    if attack_category != 'DOS' and attack_category != 'U2R_AND_R2L':\n",
        "      raise ValueError(\"Preprocess Data Fail: Invalid Attack Category\")\n",
        "    attack_data = dataset[dataset['class'] == attack_category]\n",
        "    del attack_data[\"class\"]\n",
        "    return np.array(attack_data)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fM7pjZa999Ht",
        "colab_type": "text"
      },
      "source": [
        "### IDS Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ukp0y2LiyGmy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# IDS Functions\n",
        "# get_pytoch_ids_path - Get path for PyTorch IDS Models\n",
        "def get_pytorch_ids_path(model_name, attack_category):\n",
        "    if attack_category != 'DOS' and attack_category != 'U2R_AND_R2L':\n",
        "        raise ValueError(\"Preprocess Data Fail: Invalid Attack Category\")\n",
        "    ids_path = str(f\"{IDS_Model_Path}{attack_category}/{model_name}.pth\")\n",
        "    if not os.path.exists(ids_path):\n",
        "        raise ValueError(f\"Invalid path: {ids_path}\\nNot exist file!\")\n",
        "    return ids_path\n",
        "# load_pytorch_ids_model - Load PyTorch IDS Models\n",
        "def load_pytorch_ids_model(model_name, input_dim, output_dim, attack_category):\n",
        "    ids_model = IDS_MODELS[model_name](input_dim, output_dim)\n",
        "    ids_model_path = get_pytorch_ids_path(model_name, attack_category)\n",
        "    param = th.load(ids_model_path)\n",
        "    ids_model.load_state_dict(param)\n",
        "    ids_model.eval()\n",
        "    print(f\" IDS {model_name} Loaded from: {ids_model_path}\")\n",
        "    return ids_model"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9Q5DryD-Dl0",
        "colab_type": "text"
      },
      "source": [
        "### GAN Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tV5MHCxUA-8G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# GAN Functions\n",
        "# init_generator - Khoi tao model GAN-G\n",
        "def init_generator(input_dim, output_dim, adversarial_attack_type = 1):\n",
        "    if adversarial_attack_type == 1:\n",
        "        generator = Generator_A1(input_dim, output_dim)\n",
        "    elif adversarial_attack_type == 2:\n",
        "        generator = Generator_A2(input_dim, output_dim)\n",
        "    else:\n",
        "        raise ValueError(\"Init GAN - Generator: Invalid Adversarial Attack Type\")\n",
        "    return generator\n",
        "\n",
        "# gen_adversarial_attack - Tao luu luong tan cong doi khang\n",
        "def gen_adversarial_attack(generator, noise_dim, raw_attack, attack_category, adversarial_attack_type = 1):\n",
        "    if adversarial_attack_type == 1:\n",
        "        adversarial_attack = generator(noise_dim, raw_attack, attack_category, POS_NONFUNCTIONAL_FEATURES)\n",
        "    elif adversarial_attack_type == 2:\n",
        "        batch_size = len(raw_attack)\n",
        "        noise = V(th.Tensor(np.random.uniform(0,1,(batch_size, noise_dim))))\n",
        "        generator_out = generator(noise)\n",
        "        adversarial_attack = gen_adversarial_attack_a2(generator_out, raw_attack, attack_category, POS_NONFUNCTIONAL_FEATURES)\n",
        "    else:\n",
        "        raise ValueError(\"Init GAN - Generator: Invalid Adversarial Attack Type\")\n",
        "    return adversarial_attack\n",
        "\n",
        "# train_generator - Train Generator\n",
        "def train_generator(generator, discriminator, optimizer_G, noise_dim, attack_traffic, attack_category, adversarial_attack_type):\n",
        "    for p in discriminator.parameters():  \n",
        "        p.requires_grad = False\n",
        "    optimizer_G.zero_grad()        \n",
        "    # GAN-G Generate Adversarial Attack\n",
        "    adversarial_attack = gen_adversarial_attack(generator, noise_dim, attack_traffic, attack_category, adversarial_attack_type)\n",
        "    # GAN-D predict, GAN-G update parameter\n",
        "    D_pred = discriminator(adversarial_attack)\n",
        "    g_loss = -th.mean(D_pred)\n",
        "    g_loss.backward()\n",
        "    optimizer_G.step()\n",
        "    return g_loss\n",
        "\n",
        "# train_discriminator - Train Discriminator\n",
        "def train_discriminator(discriminator, ids_model, generator, critic_iters, clamp, optimizer_D, normal_b, noise_dim, attack_traffic, attack_category, adversarial_attack_type):\n",
        "    run_d_loss = 0\n",
        "    cnt = 0\n",
        "    for p in discriminator.parameters(): \n",
        "        p.requires_grad = True\n",
        "    for c in range(critic_iters):\n",
        "        optimizer_D.zero_grad()\n",
        "        for p in discriminator.parameters():\n",
        "            p.data.clamp_(-clamp, clamp)\n",
        "        # GAN-G Generate Adversarial Attack\n",
        "        adversarial_attack = gen_adversarial_attack(generator, noise_dim, attack_traffic, attack_category, adversarial_attack_type)\n",
        "        # Make data to feed IDS\n",
        "        ids_input = th.cat((adversarial_attack,normal_b))\n",
        "        l = list(range(len(ids_input)))\n",
        "        np.random.shuffle(l)\n",
        "        ids_input = V(th.Tensor(ids_input[l]))\n",
        "        # IDS Predict\n",
        "        ids_pred = V(th.Tensor(ids_model(ids_input)))\n",
        "        ids_pred_label = th.argmax(nn.Sigmoid()(ids_pred),dim = 1).detach().numpy()\n",
        "        pred_normal = ids_input.numpy()[ids_pred_label==0]\n",
        "        pred_attack = ids_input.numpy()[ids_pred_label==1]\n",
        "        if len(pred_attack) == 0:\n",
        "            cnt += 1\n",
        "            break\n",
        "        # Make GAN-D input\n",
        "        D_noraml = discriminator(V(th.Tensor(pred_normal)))\n",
        "        D_attack= discriminator(V(th.Tensor(pred_attack)))\n",
        "        # Loss and Update Parameter\n",
        "        loss_normal = th.mean(D_noraml)\n",
        "        loss_attack = th.mean(D_attack)\n",
        "        gradient_penalty = compute_gradient_penalty(discriminator, normal_b.data, adversarial_attack.data)\n",
        "        d_loss = loss_attack - loss_normal #+ LAMBDA * gradient_penalty\n",
        "        d_loss.backward()\n",
        "        optimizer_D.step()\n",
        "        run_d_loss += d_loss.item()\n",
        "    return run_d_loss, cnt\n",
        "\n",
        "# compute_gradient_penalty - Compute Gradient Penalty\n",
        "def compute_gradient_penalty(D, normal_t, attack_t):\n",
        "    alpha = th.Tensor(np.random.random((normal_t.shape[0], 1)))\n",
        "    between_n_a = (alpha * normal_t + ((1 - alpha) * attack_t)).requires_grad_(True)\n",
        "    d_between_n_a = D(between_n_a)\n",
        "    adv = V(th.Tensor(normal_t.shape[0], 1).fill_(1.0), requires_grad=False)\n",
        "\n",
        "    gradients = autograd.grad(\n",
        "        outputs=d_between_n_a,\n",
        "        inputs=between_n_a,\n",
        "        grad_outputs=adv,\n",
        "        create_graph=True,\n",
        "        retain_graph=True,\n",
        "        only_inputs=True,\n",
        "    )[0]\n",
        "    gradients = gradients.view(gradients.size(0), -1)\n",
        "    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
        "    return gradient_penalty"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRhNLI_jSKIg",
        "colab_type": "text"
      },
      "source": [
        "### Generate Adversarial Attack Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RyrR7KLNSPtu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# cal_dr - Tinh DR\n",
        "def cal_dr(ids_model, normal, raw_attack, adversarial_attack):\n",
        "    # Make data to feed IDS contain: Attack & Normal\n",
        "    o_ids_input = th.cat((raw_attack, normal))\n",
        "    a_ids_input = th.cat((adversarial_attack,normal))\n",
        "    # Shuffle Input\n",
        "    l = list(range(len(a_ids_input)))\n",
        "    np.random.shuffle(l)\n",
        "    o_ids_input = o_ids_input[l]\n",
        "    a_ids_input = a_ids_input[l]\n",
        "    # IDS Predict Label\n",
        "    o_ids_pred = th.Tensor(ids_model(o_ids_input))\n",
        "    o_pred_label = th.argmax(nn.Sigmoid()(o_ids_pred),dim = 1).detach().numpy()\n",
        "    a_ids_pred = th.Tensor(ids_model(a_ids_input))\n",
        "    a_pred_label = th.argmax(nn.Sigmoid()(a_ids_pred),dim = 1).detach().numpy()\n",
        "    # True Label\n",
        "    ids_true_label = np.r_[np.ones(BATCH_SIZE),np.zeros(BATCH_SIZE)][l]\n",
        "    # Calc DR\n",
        "    tn1, fn1, fp1, tp1 = confusion_matrix(ids_true_label,o_pred_label).ravel()\n",
        "    tn2, fn2, fp2, tp2 = confusion_matrix(ids_true_label,a_pred_label).ravel()\n",
        "    origin_dr = tp1/(tp1 + fp1)\n",
        "    adversarial_dr = tp2/(tp2 + fp2)\n",
        "    return origin_dr, adversarial_dr"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDp5Uy_HaShp",
        "colab_type": "text"
      },
      "source": [
        "# **3. Run Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7hTHJcBcRKjg",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "ids_model_name = \"SVM\" #@param [\"DEFAULT\", \"LR\", \"SVM\", \"MLP\"]\n",
        "MAX_EPOCH = 10 #@param [\"10\", \"100\"] {type:\"raw\"}"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s8tEzhBNxvGM",
        "colab_type": "text"
      },
      "source": [
        "##**3.1 Run IDSGAN**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j01YlgClq7yq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Hyber Parameters\n",
        "BATCH_SIZE = 64\n",
        "learning_rate = 0.0001\n",
        "LAMBDA = 10\n",
        "CLAMP = 0.01\n",
        "CRITIC_ITERS = 5          # For WGAN and WGAN-GP, number of critic iters per gen iter\n",
        "\n",
        "# GAN-D\n",
        "D_INPUT_DIM = N_FEATURES\n",
        "D_OUTPUT_DIM = 1\n",
        "discriminator = Discriminator(D_INPUT_DIM,D_OUTPUT_DIM)\n",
        "optimizer_D = optim.RMSprop(discriminator.parameters(), lr=learning_rate)\n",
        "\n",
        "# GAN-G\n",
        "NOISE_DIM = 9\n",
        "G_INPUT_DIM = NOISE_DIM     # Generator input dimension is dimention of noise"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xG09yA2D9bzg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get today to set created time for GAN models\n",
        "today = str(date.today())\n",
        "\n",
        "## Prepare Dataset\n",
        "g_train_data = pd.read_csv(g_trainset_path)\n",
        "d_train_data = pd.read_csv(d_trainset_path)\n",
        "\n",
        "# All normal record in train_data\n",
        "del d_train_data[\"class\"]\n",
        "normal = np.array(d_train_data)\n",
        "\n",
        "print(\"Amout of Generator Trainset:\", g_train_data.shape[0])\n",
        "print(\"Amout of Discriminator Trainset:\", d_train_data.shape[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9C1uFo0vnv7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(f\"{40*'='} TRAINING GAN {40*'='}\")\n",
        "print(f\"{80*'='}\\n IDS Model: {ids_model_name}\")\n",
        "for attack_category in ATTACK_CATEGORIES:\n",
        "    print(f\"{80*'*'}\\n Attack Category: {attack_category}; \")\n",
        "    for adversarial_attack_type in [1,2]:\n",
        "        total_time_start = timeit.default_timer()\n",
        "        print(f\"{80*'-'}\\n Adversarial Attack Type : {adversarial_attack_type}\")\n",
        "\n",
        "        # Load PyTorch IDS Model\n",
        "        ids_model = load_pytorch_ids_model(ids_model_name, IDS_INPUT_DIM, IDS_OUTPUT_DIM, attack_category)\n",
        "        # Init GAN-G model\n",
        "        G_OUTPUT_DIM = len(POS_NONFUNCTIONAL_FEATURES[attack_category])     # Generator output is number of nonfunctional feature\n",
        "        generator = init_generator(G_INPUT_DIM,G_OUTPUT_DIM, adversarial_attack_type)\n",
        "        optimizer_G = optim.RMSprop(generator.parameters(), lr=learning_rate)\n",
        "        # Load Raw Attack Dataset\n",
        "        raw_attack = preprocess_malicious_data(g_train_data, attack_category)\n",
        "        # Prepare Save Folder\n",
        "        GAN_4IDS_Model_Path = str(f\"{GAN_Model_Path}{ids_model_name}/\")\n",
        "        if not os.path.exists(GAN_4IDS_Model_Path):\n",
        "                os.makedirs(GAN_4IDS_Model_Path)\n",
        "        GAN_G_Model_4Category_Path = str(f\"{GAN_4IDS_Model_Path}{attack_category}/Generator/{adversarial_attack_type}/\")\n",
        "        GAN_D_Model_4Category_Path = str(f\"{GAN_4IDS_Model_Path}{attack_category}/Discriminator/{adversarial_attack_type}/\")\n",
        "        for directory in [GAN_G_Model_4Category_Path, GAN_D_Model_4Category_Path]:\n",
        "            if not os.path.exists(directory):\n",
        "                os.makedirs(directory)\n",
        "\n",
        "        # Create batch of attack traffic\n",
        "        batch_attack = create_batch2(raw_attack,BATCH_SIZE)\n",
        "        # Declare Loss, DR List and Train GAN-G, GAN-D\n",
        "        d_losses,g_losses = [],[]\n",
        "        o_dr, a_dr = [],[]\n",
        "        generator.train()\n",
        "        discriminator.train()\n",
        "\n",
        "        # Start Training\n",
        "        print(f\"-->IDSGAN start training\")\n",
        "        labels = ['Epoch', 'G-Loss', 'D-Loss', 'O-DR(%)', 'A-DR(%)', 'Runtime(s)']\n",
        "        print(\"{: >10} {: >15} {: >15} {: >15} {: >15} {: >15}\".format(*labels))\n",
        "        for epoch in range(MAX_EPOCH):\n",
        "            batch_normal = create_batch2(normal,BATCH_SIZE)\n",
        "            epoch_time_start = timeit.default_timer()\n",
        "            cnt = 0\n",
        "            run_g_loss = 0.\n",
        "            run_d_loss = 0.\n",
        "            epoch_o_drs, epoch_a_drs = [], []\n",
        "\n",
        "            for idx, bn in enumerate(batch_normal):\n",
        "                normal_b = th.Tensor(bn.astype(\"float64\"))\n",
        "                attack_traffic  = V(th.Tensor(batch_attack[idx % len(batch_attack)]))\n",
        "                #  Train Generator\n",
        "                g_loss = train_generator(generator, discriminator, optimizer_G, NOISE_DIM, attack_traffic, attack_category, adversarial_attack_type)\n",
        "                run_g_loss += g_loss.item()\n",
        "\n",
        "                # Train Discriminator\n",
        "                d_loss, current_cnt = train_discriminator(discriminator, ids_model, generator, CRITIC_ITERS, CLAMP, optimizer_D, normal_b, NOISE_DIM, attack_traffic, attack_category, adversarial_attack_type)\n",
        "                run_d_loss += d_loss\n",
        "                cnt += current_cnt\n",
        "                \n",
        "                # CALC Epoch DR\n",
        "                adversarial_attack = gen_adversarial_attack(generator, NOISE_DIM, attack_traffic, attack_category, adversarial_attack_type)\n",
        "                origin_dr, adversarial_dr = cal_dr(ids_model, normal_b, attack_traffic, adversarial_attack)\n",
        "                epoch_o_drs.append(origin_dr)\n",
        "                epoch_a_drs.append(adversarial_dr)\n",
        "\n",
        "            if cnt >= (len(normal)/BATCH_SIZE):\n",
        "                print(\"Not exist predicted attack traffic\")\n",
        "                break\n",
        "            d_losses.append(run_d_loss/CRITIC_ITERS)\n",
        "            g_losses.append(run_g_loss)\n",
        "            epoch_o_dr = np.mean(epoch_o_drs)\n",
        "            epoch_a_dr = np.mean(epoch_a_drs)\n",
        "            o_dr.append(epoch_o_dr)\n",
        "            a_dr.append(epoch_a_dr)\n",
        "            \n",
        "            runtime = timeit.default_timer() - epoch_time_start\n",
        "            print_vals = [(epoch + 1), run_g_loss, (run_d_loss/CRITIC_ITERS), (epoch_o_dr*100), (epoch_a_dr*100), runtime]\n",
        "            print_string = []\n",
        "            for val in print_vals:\n",
        "                if isinstance(val, float):\n",
        "                    print_string.append(str(f\"{val:.2f}\"))\n",
        "                else:\n",
        "                    print_string.append(str(val))\n",
        "            print(\"{: >10} {: >15} {: >15} {: >15} {: >15} {: >15}\".format(*print_string))\n",
        "            # Save Adversarial Dataset each 10 epoch\n",
        "            if ((epoch + 1) % 10 == 0):\n",
        "                path = GAN_G_Model_4Category_Path + f\"{epoch + 1}epoch_time_created_{today}.pth\"\n",
        "                th.save(generator.state_dict(), path)\n",
        "                print(f\"{6*' '}-> Generator {epoch + 1} epoch is saved  to: {path}\")\n",
        "        total_runtime = timeit.default_timer() - total_time_start\n",
        "        print(f\"Training Runtime: {total_runtime:.2f}\")\n",
        "        print(\"IDSGAN finish training!\")\n",
        "        \n",
        "        # Show Graph\n",
        "        # Loss-Graph\n",
        "        plt.plot(d_losses,label = \"D_loss\")\n",
        "        plt.plot(g_losses, label = \"G_loss\")\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "        # DR-Graph\n",
        "        plt.plot(o_dr,label = \"Origin DR\")\n",
        "        plt.plot(a_dr, label = \"Adversarial DR\")\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "        # Save Model\n",
        "        path = GAN_D_Model_4Category_Path + f\"{MAX_EPOCH + 1}epoch_time_created_{today}.pth\"\n",
        "        th.save(discriminator.state_dict(), path)\n",
        "        print(f\"{6*' '}-> Saved Discrimninator {MAX_EPOCH} epoch to: {path}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQNXCNMEx1bn",
        "colab_type": "text"
      },
      "source": [
        "## **3.2 Run Generate Adversarial Traffic**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0w_F6zKcgrF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Hyber Parameters\n",
        "BATCH_SIZE = 256 # Batch size\n",
        "\n",
        "# GAN-G\n",
        "NOISE_DIM = 9\n",
        "G_INPUT_DIM = NOISE_DIM     # Generator input dimension is dimention of noise"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPx41fPd6CiW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "52159b67-3938-4ad4-a013-9b12ad4a0918"
      },
      "source": [
        "gan_model_time_created = str(date.today())\n",
        "\n",
        "# Load Testset\n",
        "testset = pd.read_csv(testset_path)\n",
        "print(f\"Amount of KDDTest+: \\t\\t{len(testset)}\")\n",
        "# test_normal\n",
        "test_normal = np.array(testset[testset[\"class\"] == 'Normal'])[:,:-1]\n",
        "# Create batch of normal traffic\n",
        "test_batch_normal = create_batch2(test_normal,BATCH_SIZE).astype('float64')\n",
        "print(f\"Amount of Normal:\\t\\t{len(test_normal)} ({len(test_batch_normal)} batchs - {BATCH_SIZE} records/batch)\")"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Amount of KDDTest+: \t\t20123\n",
            "Amount of Normal:\t\t9711 (37 batchs - 256 records/batch)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZhPpd8MCx10u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "outputId": "7407ab3d-8f77-4f15-91bc-4ffc6459b171"
      },
      "source": [
        "# Adversarial Traffic Evaluating\n",
        "print(f\"{40*'='} ADVERSARIAL TRAFFIC EVALUATING {40*'='}\")\n",
        "print(f\"{80*'='}\\n IDS Model: {ids_model_name}\")\n",
        "\n",
        "# for attack_category in ATTACK_CATEGORIES:\n",
        "for attack_category in ['DOS']:\n",
        "    for adversarial_attack_type in [1,2]:\n",
        "        print(f\"{80*'-'}\\n Adversarial Attack Type : {adversarial_attack_type}\")\n",
        "        print(f\"{5*'*'}\\n - Attack Category: {attack_category}\")\n",
        "        \n",
        "        # Load PyTorch IDS Model\n",
        "        ids_model = load_pytorch_ids_model(ids_model_name, IDS_INPUT_DIM, IDS_OUTPUT_DIM, attack_category)\n",
        "        # Init GAN-G model\n",
        "        G_OUTPUT_DIM = len(POS_NONFUNCTIONAL_FEATURES[attack_category])     # Generator output is number of nonfunctional feature\n",
        "        generator = init_generator(G_INPUT_DIM,G_OUTPUT_DIM, adversarial_attack_type)\n",
        "        # Load Attack Dataset\n",
        "        test_raw_attack = preprocess_malicious_data(testset, attack_category)\n",
        "        # Create batch of attack traffic\n",
        "        batch_attack = create_batch2(test_raw_attack, BATCH_SIZE)\n",
        "        n_batch_attack = len(batch_attack)\n",
        "        print(f\"{4*' '}Amout of {attack_category}:\\t{len(test_raw_attack)} ({n_batch_attack} batchs - {BATCH_SIZE} records/batch)\")\n",
        "        \n",
        "        # Calc DR through each epoch\n",
        "        for epoch in range(10, MAX_EPOCH + 1, 10):\n",
        "            # Load GAN-G Model\n",
        "            gan_g_model_path = str(f\"{GAN_Model_Path}{ids_model_name}/{attack_category}/Generator/{adversarial_attack_type}/{epoch}epoch_time_created_{gan_model_time_created}.pth\")\n",
        "            param = th.load(gan_g_model_path,map_location=lambda x,y:x)\n",
        "            generator.load_state_dict(param)\n",
        "            generator.eval()\n",
        "\n",
        "            o_dr,a_dr =[],[]\n",
        "            with th.no_grad():\n",
        "                for idx, bn in enumerate(test_batch_normal):\n",
        "                    normal_b = th.Tensor(bn)\n",
        "                    attack_b = th.Tensor(batch_attack[idx % n_batch_attack])\n",
        "                    # Generate Adversarial Traffic\n",
        "                    adversarial_attack_b = gen_adversarial_attack(generator, NOISE_DIM, attack_b, attack_category, adversarial_attack_type)\n",
        "\n",
        "                    # Calc DR\n",
        "                    origin_dr, adversarial_dr = cal_dr(ids_model, normal_b, attack_b, adversarial_attack_b)\n",
        "                    o_dr.append(origin_dr)\n",
        "                    a_dr.append(adversarial_dr)\n",
        "            eir = 1 - (np.mean(a_dr)/np.mean(o_dr))\n",
        "            print(f\"\\t {epoch:3d} epochs:\\tOrigin DR : {np.mean(o_dr)*100:.2f}% \\t Adversarial DR : {np.mean(a_dr)*100:.2f}% \\t EIR : {eir*100:.2f}%\")"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "======================================== ADVERSARIAL TRAFFIC EVALUATING ========================================\n",
            "================================================================================\n",
            " IDS Model: SVM\n",
            "--------------------------------------------------------------------------------\n",
            " Adversarial Attack Type : 1\n",
            "*****\n",
            " - Attack Category: DOS\n",
            " IDS SVM Loaded from: /content/drive/My Drive/Study/KLTN/Saved Model/IDSModel/DOS/SVM.pth\n",
            "    Amout of DOS:\t7460 (29 batchs - 256 records/batch)\n",
            "\t  10 epochs:\tOrigin DR : 73.10% \t Adversarial DR : 18.91% \t EIR : 74.13%\n",
            "--------------------------------------------------------------------------------\n",
            " Adversarial Attack Type : 2\n",
            "*****\n",
            " - Attack Category: DOS\n",
            " IDS SVM Loaded from: /content/drive/My Drive/Study/KLTN/Saved Model/IDSModel/DOS/SVM.pth\n",
            "    Amout of DOS:\t7460 (29 batchs - 256 records/batch)\n",
            "\t  10 epochs:\tOrigin DR : 72.58% \t Adversarial DR : 19.90% \t EIR : 72.58%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwWugTozppL5",
        "colab_type": "text"
      },
      "source": [
        "The Saved Model stored in [Google Drive - GAN Model](https://drive.google.com/drive/u/1/folders/1VNFW-k5SbR0eGsJ_np3U-W3Rcz_n4I8N)\n",
        "\n",
        "The Result of Code stored in [Github - Thesis](https://github.com/thetinybug/thesis-IDSGAN)"
      ]
    }
  ]
}